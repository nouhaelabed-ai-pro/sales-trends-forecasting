{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Prediction Model using XGBoost\n",
    "\n",
    "In this notebook, we'll build a sales prediction model using XGBoost. We'll:\n",
    "1. Load and preprocess the data\n",
    "2. Prepare features and target\n",
    "3. Train the XGBoost model\n",
    "4. Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('../data/cleaned_superstore_sales.csv')\n",
    "\n",
    "# Drop ID columns and Postal Code\n",
    "columns_to_drop = ['Row ID', 'Order ID', 'Customer ID', 'Postal Code']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "date_columns = ['Order Date', 'Ship Date']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], format='mixed', dayfirst=True)\n",
    "\n",
    "print(\"Dataset shape after dropping columns:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract date features\n",
    "def extract_date_features(df, date_column):\n",
    "    df[f'{date_column}_Year'] = df[date_column].dt.year\n",
    "    df[f'{date_column}_Month'] = df[date_column].dt.month\n",
    "    df[f'{date_column}_Quarter'] = df[date_column].dt.quarter\n",
    "    df[f'{date_column}_DayOfWeek'] = df[date_column].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "# Extract features from both date columns\n",
    "df = extract_date_features(df, 'Order Date')\n",
    "df = extract_date_features(df, 'Ship Date')\n",
    "\n",
    "# Drop original date columns\n",
    "df = df.drop(columns=date_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Encode categorical variables\n",
    "categorical_columns = ['Ship Mode', 'Customer Segment', 'Category', 'Sub-Category', 'Region', 'Country', 'State', 'City']\n",
    "\n",
    "# Initialize dictionary to store label encoders\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode each categorical column\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Sales', axis=1)\n",
    "y = df['Sales']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize and train XGBoost model\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_metric='rmse',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error: ${rmse:.2f}')\n",
    "print(f'RÂ² Score: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    feature_importance.head(15), \n",
    "    x='importance', \n",
    "    y='feature',\n",
    "    title='Top 15 Most Important Features',\n",
    "    orientation='h'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot actual vs predicted values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "fig = px.scatter(\n",
    "    comparison_df,\n",
    "    x='Actual',\n",
    "    y='Predicted',\n",
    "    title='Actual vs Predicted Sales',\n",
    "    labels={'Actual': 'Actual Sales ($)', 'Predicted': 'Predicted Sales ($)'}\n",
    ")\n",
    "\n",
    "# Add perfect prediction line\n",
    "fig.add_scatter(\n",
    "    x=[comparison_df.Actual.min(), comparison_df.Actual.max()],\n",
    "    y=[comparison_df.Actual.min(), comparison_df.Actual.max()],\n",
    "    mode='lines',\n",
    "    name='Perfect Prediction',\n",
    "    line=dict(dash='dash')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
